1684399945.3456352
Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])
Shape of y: torch.Size([64]) torch.int64
Using cuda device
NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)
Load model ./model/MNIST_model.pth
CNN(
  (CNN_stack): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU()
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_stack): Sequential(
    (0): Linear(in_features=3136, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=512, bias=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): ReLU()
    (5): Linear(in_features=512, out_features=10, bias=True)
  )
)
Epoch 1
-------------------------------
loss: 2.304226  [   64/60000]
loss: 2.289200  [ 6464/60000]
loss: 2.289797  [12864/60000]
loss: 2.249202  [19264/60000]
loss: 2.221031  [25664/60000]
loss: 2.052895  [32064/60000]
loss: 1.329703  [38464/60000]
loss: 0.996770  [44864/60000]
loss: 0.822473  [51264/60000]
loss: 0.687910  [57664/60000]
Test Error: 
 Accuracy: 85.5%, Avg loss: 0.478629 

Epoch 2
-------------------------------
loss: 0.668958  [   64/60000]
loss: 0.456700  [ 6464/60000]
loss: 0.455436  [12864/60000]
loss: 0.384158  [19264/60000]
loss: 0.332598  [25664/60000]
loss: 0.357646  [32064/60000]
loss: 0.276050  [38464/60000]
loss: 0.415862  [44864/60000]
loss: 0.555423  [51264/60000]
loss: 0.308064  [57664/60000]
Test Error: 
 Accuracy: 92.3%, Avg loss: 0.246387 

Epoch 3
-------------------------------
loss: 0.250196  [   64/60000]
loss: 0.356077  [ 6464/60000]
loss: 0.223463  [12864/60000]
loss: 0.312844  [19264/60000]
loss: 0.195137  [25664/60000]
loss: 0.299196  [32064/60000]
loss: 0.125539  [38464/60000]
loss: 0.377869  [44864/60000]
loss: 0.330125  [51264/60000]
loss: 0.288542  [57664/60000]
Test Error: 
 Accuracy: 94.7%, Avg loss: 0.173175 

Epoch 4
-------------------------------
loss: 0.139282  [   64/60000]
loss: 0.191634  [ 6464/60000]
loss: 0.164136  [12864/60000]
loss: 0.262051  [19264/60000]
loss: 0.123077  [25664/60000]
loss: 0.222308  [32064/60000]
loss: 0.073347  [38464/60000]
loss: 0.391918  [44864/60000]
loss: 0.328370  [51264/60000]
loss: 0.235301  [57664/60000]
Test Error: 
 Accuracy: 96.0%, Avg loss: 0.133373 

Epoch 5
-------------------------------
loss: 0.132945  [   64/60000]
loss: 0.129194  [ 6464/60000]
loss: 0.089865  [12864/60000]
loss: 0.213201  [19264/60000]
loss: 0.077883  [25664/60000]
loss: 0.205997  [32064/60000]
loss: 0.062572  [38464/60000]
loss: 0.325588  [44864/60000]
loss: 0.282406  [51264/60000]
loss: 0.245319  [57664/60000]
Test Error: 
 Accuracy: 97.0%, Avg loss: 0.101399 

Epoch 6
-------------------------------
loss: 0.073159  [   64/60000]
loss: 0.175446  [ 6464/60000]
loss: 0.127091  [12864/60000]
loss: 0.182531  [19264/60000]
loss: 0.053360  [25664/60000]
loss: 0.174309  [32064/60000]
loss: 0.080566  [38464/60000]
loss: 0.233831  [44864/60000]
loss: 0.245807  [51264/60000]
loss: 0.205349  [57664/60000]
Test Error: 
 Accuracy: 97.1%, Avg loss: 0.089271 

Epoch 7
-------------------------------
loss: 0.074346  [   64/60000]
loss: 0.115148  [ 6464/60000]
loss: 0.099374  [12864/60000]
loss: 0.147379  [19264/60000]
loss: 0.047357  [25664/60000]
loss: 0.102569  [32064/60000]
loss: 0.069743  [38464/60000]
loss: 0.266079  [44864/60000]
loss: 0.195961  [51264/60000]
loss: 0.196710  [57664/60000]
Test Error: 
 Accuracy: 97.5%, Avg loss: 0.079017 

Epoch 8
-------------------------------
loss: 0.054136  [   64/60000]
loss: 0.131718  [ 6464/60000]
loss: 0.087384  [12864/60000]
loss: 0.114889  [19264/60000]
loss: 0.077775  [25664/60000]
loss: 0.146442  [32064/60000]
loss: 0.063105  [38464/60000]
loss: 0.208966  [44864/60000]
loss: 0.178136  [51264/60000]
loss: 0.213045  [57664/60000]
Test Error: 
 Accuracy: 97.8%, Avg loss: 0.068882 

Epoch 9
-------------------------------
loss: 0.038766  [   64/60000]
loss: 0.102903  [ 6464/60000]
loss: 0.063440  [12864/60000]
loss: 0.079587  [19264/60000]
loss: 0.045896  [25664/60000]
loss: 0.115535  [32064/60000]
loss: 0.063801  [38464/60000]
loss: 0.165920  [44864/60000]
loss: 0.205319  [51264/60000]
loss: 0.162373  [57664/60000]
Test Error: 
 Accuracy: 97.9%, Avg loss: 0.066221 

Epoch 10
-------------------------------
loss: 0.041334  [   64/60000]
loss: 0.106132  [ 6464/60000]
loss: 0.073945  [12864/60000]
loss: 0.089376  [19264/60000]
loss: 0.062024  [25664/60000]
loss: 0.066386  [32064/60000]
loss: 0.072823  [38464/60000]
loss: 0.178994  [44864/60000]
loss: 0.159830  [51264/60000]
loss: 0.145452  [57664/60000]
Test Error: 
 Accuracy: 98.1%, Avg loss: 0.059453 

Epoch 11
-------------------------------
loss: 0.022860  [   64/60000]
loss: 0.057722  [ 6464/60000]
loss: 0.064356  [12864/60000]
loss: 0.066430  [19264/60000]
loss: 0.025972  [25664/60000]
loss: 0.060744  [32064/60000]
loss: 0.053469  [38464/60000]
loss: 0.188551  [44864/60000]
loss: 0.108263  [51264/60000]
loss: 0.151525  [57664/60000]
Test Error: 
 Accuracy: 98.3%, Avg loss: 0.052627 

Epoch 12
-------------------------------
loss: 0.034555  [   64/60000]
loss: 0.093583  [ 6464/60000]
loss: 0.048785  [12864/60000]
loss: 0.064087  [19264/60000]
loss: 0.037616  [25664/60000]
loss: 0.077970  [32064/60000]
loss: 0.054209  [38464/60000]
loss: 0.118476  [44864/60000]
loss: 0.096778  [51264/60000]
loss: 0.141211  [57664/60000]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.050862 

Epoch 13
-------------------------------
loss: 0.021366  [   64/60000]
loss: 0.085160  [ 6464/60000]
loss: 0.079957  [12864/60000]
loss: 0.073156  [19264/60000]
loss: 0.026586  [25664/60000]
loss: 0.092537  [32064/60000]
loss: 0.044594  [38464/60000]
loss: 0.091967  [44864/60000]
loss: 0.153341  [51264/60000]
loss: 0.121386  [57664/60000]
Test Error: 
 Accuracy: 98.4%, Avg loss: 0.048778 

Epoch 14
-------------------------------
loss: 0.019031  [   64/60000]
loss: 0.093348  [ 6464/60000]
loss: 0.034097  [12864/60000]
loss: 0.053777  [19264/60000]
loss: 0.017304  [25664/60000]
loss: 0.048984  [32064/60000]
loss: 0.059596  [38464/60000]
loss: 0.094672  [44864/60000]
loss: 0.120181  [51264/60000]
loss: 0.106612  [57664/60000]
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.043948 

Epoch 15
-------------------------------
loss: 0.016155  [   64/60000]
loss: 0.066374  [ 6464/60000]
loss: 0.072903  [12864/60000]
loss: 0.013539  [19264/60000]
loss: 0.016592  [25664/60000]
loss: 0.033205  [32064/60000]
loss: 0.039866  [38464/60000]
loss: 0.130051  [44864/60000]
loss: 0.080783  [51264/60000]
loss: 0.107599  [57664/60000]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.044168 

Epoch 16
-------------------------------
loss: 0.023092  [   64/60000]
loss: 0.059374  [ 6464/60000]
loss: 0.077044  [12864/60000]
loss: 0.052785  [19264/60000]
loss: 0.020614  [25664/60000]
loss: 0.052308  [32064/60000]
loss: 0.059962  [38464/60000]
loss: 0.134724  [44864/60000]
loss: 0.102186  [51264/60000]
loss: 0.104174  [57664/60000]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.042007 

Epoch 17
-------------------------------
loss: 0.020934  [   64/60000]
loss: 0.057907  [ 6464/60000]
loss: 0.054641  [12864/60000]
loss: 0.069180  [19264/60000]
loss: 0.017513  [25664/60000]
loss: 0.024463  [32064/60000]
loss: 0.051538  [38464/60000]
loss: 0.097612  [44864/60000]
loss: 0.090694  [51264/60000]
loss: 0.111321  [57664/60000]
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.041146 

Epoch 18
-------------------------------
loss: 0.034587  [   64/60000]
loss: 0.055191  [ 6464/60000]
loss: 0.055846  [12864/60000]
loss: 0.033314  [19264/60000]
loss: 0.020017  [25664/60000]
loss: 0.039462  [32064/60000]
loss: 0.020381  [38464/60000]
loss: 0.104966  [44864/60000]
loss: 0.078883  [51264/60000]
loss: 0.094171  [57664/60000]
Test Error: 
 Accuracy: 98.7%, Avg loss: 0.038877 

Epoch 19
-------------------------------
loss: 0.010815  [   64/60000]
loss: 0.119681  [ 6464/60000]
loss: 0.056922  [12864/60000]
loss: 0.027861  [19264/60000]
loss: 0.012954  [25664/60000]
loss: 0.041096  [32064/60000]
loss: 0.062925  [38464/60000]
loss: 0.081470  [44864/60000]
loss: 0.100062  [51264/60000]
loss: 0.123828  [57664/60000]
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.036839 

Epoch 20
-------------------------------
loss: 0.014490  [   64/60000]
loss: 0.084478  [ 6464/60000]
loss: 0.035767  [12864/60000]
loss: 0.050884  [19264/60000]
loss: 0.024561  [25664/60000]
loss: 0.023798  [32064/60000]
loss: 0.070487  [38464/60000]
loss: 0.057672  [44864/60000]
loss: 0.087368  [51264/60000]
loss: 0.098168  [57664/60000]
Test Error: 
 Accuracy: 98.7%, Avg loss: 0.036354 

Done!
Time-consuming: 329.3340837955475 

Saved PyTorch CNN Model State to ./model/MNIST_CNN_model_3.pth
CNN(
  (CNN_stack): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU()
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_stack): Sequential(
    (0): Linear(in_features=3136, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=512, bias=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): ReLU()
    (5): Linear(in_features=512, out_features=10, bias=True)
  )
)
Predicted: "7", Actual: "7"
